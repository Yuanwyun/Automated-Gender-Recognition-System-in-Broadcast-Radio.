# Automated-Gender-Recognition-System-in-Broadcast-Radio.

The dataset used to train the neural network for this project is Common Voice from Kaggle, which is based on many sources from the public domain, such as films and public lectures, it supports the training and testing of automatic speech recognition (ASR) systems. The database is compliant with the CC0 license.

AIM: 

In 2015 Irish Radio highlighted the importance of the female voice and suggested that there should be a balance of male and female speaking time on air. Previous surveys have shown that 72% of radio are from male and 28% from female, with women being under-represented on factual radio programming [1]. Thus, the gender-equality campaign group “Women on Air” was set up to call for more women to be heard on air. Currently there is a lack of data on how much Irish news and broadcasters made progress on female presentations [2]. A system that measures the ratio of male to female voices on the radio will assist in recording this data. With this aim in mind, the objective of this final year project is to determine the gender of the speaker through speech recognition technology and calculate the percentage of male and female in a broadcast audio through gender speaker diarisation
This project deals with basic speech principles such as the propagation and characteristics of speech signals, the human auditory system, and the differences between male and female voices. The main implementation of the project is divided into three sections: gender recognition, gender speaker diarisation and testing session respectively. Primarily, a feed- forward neural network is used for the implementation of voice gender recognition technology. The advantage of neural network as a better solution compared to other technologies for speech recognition systems is that it makes speech recognition more accurate and can be improved by increasing training data and optimizing the model. The database used for the neural network has a sample size of 66,938 which contains an equal number of male and female audio files. The system uses the Mel-Spectrogram to extract features from the audio files to calculate the gender probabilities. Ultimately the neural network measures the probability of being male and female in a single gender audio file and draws conclusions.


In terms of technical implementation, the original plan for the project was to use an SVM (Support Vector Machine) model for sound gender recognition and use the MFCC feature extraction method. However, after completing the SVM model and testing it, the training and testing accuracies obtained were 78.2% and 76.8% respectively with 50000 training samples and 10000 test samples. A neural network can be tested with a similar number of training samples (53500) and a training accuracy of around 90%. The final decision was to use a feed- forward neural network for voice gender recognition and Mel-spectrogram method for voice feature extraction. A silence detector, an algorithm to randomly select a certain number of files and merge them, an algorithm to convert mp3 files to wav files, and a code section to remove the mute from the audio (used optionally) were also added to the speaker diarisation section. In the testing section, for different randomly joined files the system can automatically generate a ground truth based on the files names that include the gender for each respective audio file – and print the ground truth for every chunk.

